{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "Heart_Attack_Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.6 64-bit"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "6426af1756cc9b74662456eba67783cc797322f9db2593e932cfc690cc6420a6"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 53,
      "source": [
        "import os\r\n",
        "import numpy as np, seaborn as sns\r\n",
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from sklearn.cluster import AgglomerativeClustering\r\n",
        "from sklearn.cluster import KMeans\r\n",
        "from scipy.cluster import hierarchy\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "#importing Heart  Data\r\n",
        "Heart_Data = pd.read_csv(r'heart.csv')\r\n",
        "Heart_Data"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'heart.csv'",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1748/1427350088.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m#importing Heart  Data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mHeart_Data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'heart.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mHeart_Data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \"\"\"\n\u001b[1;32m--> 222\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    699\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    700\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 701\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    702\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    703\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'heart.csv'"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "gIcTUdWbJTDb",
        "outputId": "4d2df80b-9bed-4bf1-89a4-1406d1c496e4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Initial Exploration\r\n",
        "# Number of rows\r\n",
        "print(Heart_Data.shape[0])\r\n",
        "\r\n",
        "# Column names\r\n",
        "col=Heart_Data.columns.tolist()\r\n",
        "print(Heart_Data.columns.tolist())\r\n",
        "\r\n",
        "# Data types\r\n",
        "print(Heart_Data.dtypes)\r\n"
      ],
      "outputs": [],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-03-19T23:17:24.151607Z",
          "start_time": "2017-03-19T19:17:24.105167-04:00"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "run_control": {
          "marked": true
        },
        "id": "ypwEpmjeZlXF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfc17ecd-882b-4da5-bac2-848ccfd59a43"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Data Cleaning \r\n",
        "#Check if there are some null values\r\n",
        "Heart_Data.isnull().sum().sort_values()\r\n",
        "Heart_Data.shape"
      ],
      "outputs": [],
      "metadata": {
        "id": "525XKuFFvMRM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72e6a682-83a5-4c76-866f-da17f7808893"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Create dummies variables\r\n",
        "#thall column\r\n",
        "Heart_Data['thall'].value_counts()\r\n",
        "thall_dum=pd.get_dummies(Heart_Data['thall'])\r\n",
        "\r\n",
        "thall_dum = thall_dum.set_axis(['thall_None', 'thall_Fixed_Defect', 'thall_Normal','thall_Reversable'], axis=1)\r\n",
        "print(thall_dum)\r\n",
        "#Slope column\r\n",
        "Heart_Data['slp'].value_counts()\r\n",
        "slope_dum=pd.get_dummies(Heart_Data['slp'])\r\n",
        "\r\n",
        "slope_dum = slope_dum.set_axis(['slp_Downsloping', 'slp_Flat', 'slp_Upsloping'], axis=1)\r\n",
        "print(slope_dum)\r\n",
        "#Chest Pain column\r\n",
        "Heart_Data['cp'].value_counts()\r\n",
        "chest_pain_dum=pd.get_dummies(Heart_Data['cp'])\r\n",
        "\r\n",
        "chest_pain_dum = chest_pain_dum.set_axis(['cp_asymptomatic', 'cp_typical_angina', 'cp_atypical_angina','cp_no_angina'], axis=1)\r\n",
        "print(chest_pain_dum)\r\n",
        "#Rest Ecg column\r\n",
        "Heart_Data['restecg'].value_counts()\r\n",
        "rest_ecg=pd.get_dummies(Heart_Data['restecg'])\r\n",
        "\r\n",
        "rest_ecg = rest_ecg.set_axis(['restecg_hypetrophic', 'restecg_normal', 'restecg_abnormal'], axis=1)\r\n",
        "print(rest_ecg)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fwT3cbv3ODw",
        "outputId": "14773252-e2e7-4b59-f77c-519dabcee8b8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Edit Data Frame\r\n",
        "Heart_Data_bk=Heart_Data\r\n",
        "Heart_Data=Heart_Data.drop(columns=['slp','thall','restecg','cp'])\r\n",
        "target=Heart_Data['output']\r\n",
        "Heart_Data= Heart_Data.join(rest_ecg)\r\n",
        "Heart_Data= Heart_Data.join(chest_pain_dum)\r\n",
        "Heart_Data= Heart_Data.join(thall_dum)\r\n",
        "Heart_Data= Heart_Data.join(slope_dum)"
      ],
      "outputs": [],
      "metadata": {
        "id": "mDdxTRFcL8w9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "Heart_Data\r\n",
        "y=Heart_Data['output']\r\n",
        "fields = list(Heart_Data.drop(columns='output'))  # everything except \"output\"\r\n",
        "correlations = Heart_Data[fields].corrwith(y)\r\n",
        "correlations.sort_values(inplace=True)\r\n",
        "correlations"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "1o3Drq6FOjKn",
        "outputId": "5b87e6e7-2176-4ef0-8a19-8445e589c9a2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "os.chdir(r\"C:\\Users\\gdelprat\\OneDrive - Capgemini\\Desktop\\Corsi\\Coursera ML\\Supervised_ML_Class\\Data\")\r\n",
        "\r\n",
        "from colorsetup import colors, palette\r\n",
        "sns.set_palette(palette)\r\n",
        "sns.set_context('talk')\r\n",
        "sns.set_palette(palette)\r\n",
        "sns.set_style('white')\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "#ns.pairplot(Heart_Data)\r\n",
        "sns.barplot(fields,correlations)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Numerical Data\r\n",
        "Heart_Data.describe()"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "eGp02uPHPtMv",
        "outputId": "e66e25ca-e0f0-4611-8414-9c90d7456d33"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Create a functions to plot multiple bar charts\r\n",
        "def hist_loop(data: pd.DataFrame,\r\n",
        "              rows: int,\r\n",
        "              cols: int,\r\n",
        "              figsize: tuple):\r\n",
        "    fig, axes = plt.subplots(rows,cols, figsize=figsize)\r\n",
        "    for i, ax in enumerate(axes.flatten()):\r\n",
        "        if i < len(data.columns):\r\n",
        "            data[sorted(data.columns)[i]].plot.hist(bins=30, ax=ax)\r\n",
        "            ax.set_title(f'{sorted(data.columns)[i]} distribution', fontsize=10)\r\n",
        "            ax.tick_params(axis='x', labelsize=10)\r\n",
        "            ax.tick_params(axis='y', labelsize=10)\r\n",
        "            ax.get_yaxis().get_label().set_visible(False)\r\n",
        "        else:\r\n",
        "            fig.delaxes(ax=ax)\r\n",
        "    fig.tight_layout()\r\n",
        "\r\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "knIoePajQlne"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "Heart_Data_num=Heart_Data_bk.drop(columns=['slp','thall','restecg','cp','sex','output','caa','exng','fbs'])\r\n",
        "hist_loop(data=Heart_Data_num,\r\n",
        "          rows=3,\r\n",
        "          cols=3,\r\n",
        "          figsize=(20,10))"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "BjU5X1uPQnq2",
        "outputId": "dc3ce281-00cb-4cda-c2d6-492ee4728f51"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Perform log transformation\r\n",
        "for col in Heart_Data_num.columns.values:\r\n",
        "    Heart_Data_num['log_' + col] = Heart_Data_num[col].apply(np.log1p)\r\n",
        "Heart_Data_num"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "rCkUmAQth75i",
        "outputId": "568a1242-0c9b-4f39-9b56-d825b0cd49ee"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "log_df = Heart_Data_num.filter(regex='^log_', axis=1)\r\n",
        "hist_loop(data=log_df,\r\n",
        "          rows=3,\r\n",
        "          cols=3,\r\n",
        "          figsize=(20,10))\r\n",
        "\r\n",
        "\r\n",
        "Heart_Data_num_log=Heart_Data_num.drop(columns=['age','chol','trtbps','thalachh','oldpeak'])"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "UqudnyEukIBR",
        "outputId": "b1c09d19-02d8-4674-eab4-60656b54296c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Join log data with categorical data\r\n",
        "Heart_Data=Heart_Data.drop(columns=['age','chol','trtbps','thalachh','oldpeak'])\r\n",
        "Heart_Data_Fin=Heart_Data.join(Heart_Data_num_log)\r\n",
        "Heart_Data_Fin.to_csv('Heart_Data_Clean.csv',index='False')\r\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "OW9k62zwmhi1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Hypothesis Testing \r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "from scipy.stats import ttest_ind, t\r\n",
        "import math\r\n",
        "\r\n",
        "s1= Heart_Data_Fin['log_age']\r\n",
        "s2= Heart_Data_Fin['log_chol']\r\n",
        "\r\n",
        "result = ttest_ind(s1, s2, equal_var=False)\r\n",
        "print(\"t-value\" + \" \"+ str(result.statistic))\r\n",
        "print(\"p-value\" + \" \" + str(result.pvalue))"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ruiRNE2vqY_h",
        "outputId": "497ed7f1-5ba9-4dd3-bd0f-ff78f0f5cc84"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "s3= Heart_Data_Fin['log_age']\r\n",
        "s4= Heart_Data_Fin['log_trtbps']\r\n",
        "\r\n",
        "result2 = ttest_ind(s3, s4, equal_var=False)\r\n",
        "print(\"t-value\" + \" \"+ str(result2.statistic))\r\n",
        "print(\"p-value\" + \" \" + str(result2.pvalue))"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwcT4JNT4n13",
        "outputId": "aec798d8-95ec-43ff-837f-e7f7f32a1b34"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\r\n",
        "from sklearn.model_selection import KFold, cross_val_predict\r\n",
        "from sklearn.linear_model import LinearRegression, Lasso, Ridge\r\n",
        "from sklearn.metrics import r2_score\r\n",
        "from sklearn.pipeline import Pipeline\r\n",
        "\r\n",
        "\r\n",
        "#Regression  \r\n",
        "x=Heart_Data_Fin.drop(columns='output')\r\n",
        "y=Heart_Data_Fin['output']\r\n",
        "print(y)\r\n",
        "#K-Fold\r\n",
        "kf = KFold(shuffle=True, random_state=72018, n_splits=3)\r\n"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-t0Y3AAf6jSe",
        "outputId": "5b2a5497-2ea4-4544-eb05-215edcc25469"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from sklearn.metrics import r2_score, mean_squared_error\r\n",
        "#Linear Regression\r\n",
        "# vanilla regression and K-fold cross validation\r\n",
        "s = StandardScaler()\r\n",
        "lr = LinearRegression()\r\n",
        "scores = []\r\n",
        "lr = LinearRegression()\r\n",
        "\r\n",
        "for train_index, test_index in kf.split(x):\r\n",
        "    X_train, X_test, y_train, y_test = (x.iloc[train_index, :], \r\n",
        "                                        x.iloc[test_index, :], \r\n",
        "                                        y[train_index], \r\n",
        "                                        y[test_index])\r\n",
        "    \r\n",
        "    lr.fit(X_train, y_train)\r\n",
        "        \r\n",
        "    y_pred = lr.predict(X_test)\r\n",
        "\r\n",
        "    score = r2_score(y_test.values, y_pred)\r\n",
        "    \r\n",
        "    scores.append(score)\r\n",
        "    \r\n",
        "scores\r\n",
        "\r\n",
        "# with pipeline\r\n",
        "estimator = Pipeline([(\"scaler\", s),(\"regression\", lr)])\r\n",
        "predictions_lr = cross_val_predict(estimator, X_train, y_train, cv=kf)\r\n",
        "linear_score = r2_score(y_train, predictions_lr)\r\n",
        "\r\n",
        "linear_score, score #almost identical"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rw3uSVDzbWB1",
        "outputId": "f226cc7c-a5ed-4d10-cdaa-98d301a1cc99"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Adding Polynomial Tranformations\r\n",
        "\r\n",
        "# lasso regression and K-fold cross validation\r\n",
        "s = StandardScaler()\r\n",
        "pf = PolynomialFeatures(degree=2)\r\n",
        "kf = KFold(shuffle=True, random_state=72018, n_splits=3)\r\n",
        "scores = []\r\n",
        "alphas = np.arange(10e-2, 1, 0.1)\r\n",
        "predictions_lsr = []\r\n",
        "for alpha in alphas:\r\n",
        "    las = Lasso(alpha=alpha, max_iter=100000)\r\n",
        "    \r\n",
        "    estimator = Pipeline([\r\n",
        "        (\"scaler\", s),\r\n",
        "        (\"make_higher_degree\", pf),\r\n",
        "        (\"lasso_regression\", las)])\r\n",
        "\r\n",
        "    predictions_lsr = cross_val_predict(estimator, X_train, y_train, cv = kf)\r\n",
        "    \r\n",
        "    score = r2_score(y_train, predictions_lsr)\r\n",
        "    \r\n",
        "    scores.append(score)\r\n",
        "plt.semilogx(alphas, scores, '-o', color='purple')\r\n",
        "plt.title('Lasso Regression')\r\n",
        "plt.xlabel('$\\\\alpha$')\r\n",
        "plt.ylabel('$R^2$');"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "eh0C5Jz1cfiu",
        "outputId": "b22d753e-18eb-429b-d103-bb380da2b9e9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "best_estimator = Pipeline([\r\n",
        "                    (\"scaler\", s),\r\n",
        "                    (\"make_higher_degree\", PolynomialFeatures(degree=2)),\r\n",
        "                    (\"lasso_regression\", Lasso(alpha=0.03))])\r\n",
        "\r\n",
        "best_estimator.fit(X_train, y_train)\r\n",
        "lasso_score = best_estimator.score(X_train, y_train)\r\n",
        "lasso_score"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9823X_2ekBNo",
        "outputId": "9c9cfe4a-b1ac-4e16-da19-aadbc3500e48"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# ridge regression and K-fold cross validation\r\n",
        "pf = PolynomialFeatures(degree=2)\r\n",
        "alphas = np.arange(10e-2, 1, 0.1)\r\n",
        "scores=[]\r\n",
        "predictions_rr = []\r\n",
        "for alpha in alphas:\r\n",
        "    ridge = Ridge(alpha=alpha, max_iter=100000)\r\n",
        "\r\n",
        "    estimator = Pipeline([\r\n",
        "        (\"scaler\", s),\r\n",
        "        (\"polynomial_features\", pf),\r\n",
        "        (\"ridge_regression\", ridge)])\r\n",
        "\r\n",
        "    predictions_rr = cross_val_predict(estimator, X_train, y_train, cv = kf)\r\n",
        "    score = r2_score(y_train, predictions_rr)\r\n",
        "    scores.append(score)\r\n",
        "\r\n",
        "plt.plot(alphas, scores, '-o', color='purple')\r\n",
        "plt.title('Ridge Regression')\r\n",
        "plt.xlabel('$\\\\alpha$')\r\n",
        "plt.ylabel('$R^2$');"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "08n9La94sBt1",
        "outputId": "8e472bd2-a5c5-483c-b37e-2dad016f9226"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "\r\n",
        "best_estimator = Pipeline([\r\n",
        "                    (\"scaler\", s),\r\n",
        "                    (\"make_higher_degree\", PolynomialFeatures(degree=2)),\r\n",
        "                    (\"ridge_regression\", Ridge(alpha=0.03))])\r\n",
        "\r\n",
        "best_estimator.fit(X_train, y_train)\r\n",
        "ridge_score = best_estimator.score(X_train, y_train)\r\n",
        "# comparing scores\r\n",
        "pd.DataFrame([[linear_score, lasso_score, ridge_score]],columns=['linear', 'lasso', 'ridge'], index=['score'])"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "HOvrjFrwsRji",
        "outputId": "88d622ee-3ebd-4a14-a89c-240a4d1b2b72"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Logistic Regression\r\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, precision_score, f1_score, roc_auc_score\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.neighbors import KNeighborsClassifier\r\n",
        "from sklearn.tree import DecisionTreeClassifier\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "from sklearn.metrics import precision_recall_fscore_support as score\r\n",
        "#Dataframe for metrics\r\n",
        "metrics = pd.DataFrame()\r\n",
        "\r\n",
        "# Standard logistic regression\r\n",
        "lr = LogisticRegression(solver='liblinear').fit(X_train, y_train)\r\n",
        "y_pred_lr = lr.predict(X_test)\r\n",
        "\r\n",
        "precision_lr, recall_lr = (round(float(x),2) for x in list(score(y_test,\r\n",
        "                                                                    y_pred_lr,\r\n",
        "                                                                    average='weighted'))[:-2])\r\n",
        "# writing all lr stats to metrics DataFrame\r\n",
        "lr_stats = pd.Series({'precision':precision_lr,\r\n",
        "                      'recall':recall_lr,\r\n",
        "                      'accuracy':round(accuracy_score(y_test, y_pred_lr), 2),\r\n",
        "                      'f1score':round(f1_score(y_test, y_pred_lr), 2),\r\n",
        "                      'auc': round(roc_auc_score(y_test, y_pred_lr),2)},\r\n",
        "                     name='Logistic Regression')\r\n",
        "# Report outcomes\r\n",
        "pd.DataFrame(classification_report(y_test, y_pred_lr, output_dict=True)).iloc[:3,:2]"
      ],
      "outputs": [],
      "metadata": {
        "id": "NilfejgFzWFk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#K Nearest Neighbors model\r\n",
        "\r\n",
        "knn=KNeighborsClassifier(n_neighbors=3 , weights='distance')\r\n",
        "knn = knn.fit(X_train,y_train)\r\n",
        "y_pred_knn=knn.predict(X_test)\r\n",
        "precision_knn, recall_knn = (round(float(x),2) for x in list(score(y_test,y_pred_knn,average='weighted'))[:-2])\r\n",
        "# adding KNN stats to metrics DataFrame\r\n",
        "knn_stats = pd.Series({'precision':precision_knn,\r\n",
        "                      'recall':recall_knn,\r\n",
        "                      'accuracy':round(accuracy_score(y_test, y_pred_knn), 2),\r\n",
        "                      'f1score':round(f1_score(y_test, y_pred_knn), 2),\r\n",
        "                      'auc': round(roc_auc_score(y_test, y_pred_knn),2)}, name='KNN')\r\n",
        "# Report outcomes\r\n",
        "pd.DataFrame(classification_report(y_test, y_pred_knn, output_dict=True)).iloc[:3,:2]"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "\r\n",
        "# Initialize the random forest estimator\r\n",
        "RF = RandomForestClassifier(oob_score=True, \r\n",
        "                            random_state=42, \r\n",
        "                            warm_start=True,\r\n",
        "                            n_jobs=-1)\r\n",
        "\r\n",
        "# initialise list for out of bag error\r\n",
        "oob_list = list()\r\n",
        "\r\n",
        "# Iterate through all of the possibilities for number of trees\r\n",
        "for n_trees in [15, 20, 30, 40, 50, 100, 150, 200, 300, 400, 500 ,600 , 700, 800 , 900,1000,1200,1900]:\r\n",
        "    \r\n",
        "    # Use this to set the number of trees\r\n",
        "    RF.set_params(n_estimators=n_trees)\r\n",
        "    \r\n",
        "    # Fit the model\r\n",
        "    RF.fit(X_train, y_train)\r\n",
        "    \r\n",
        "    # Get the out of bag error and store it\r\n",
        "    oob_error = 1 - RF.oob_score_\r\n",
        "    oob_list.append(pd.Series({'n_trees': n_trees, 'oob': oob_error}))\r\n",
        "\r\n",
        "rf_oob_df = pd.concat(oob_list, axis=1).T.set_index('n_trees')"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "sns.set_context('talk')\r\n",
        "sns.set_style('white')\r\n",
        "\r\n",
        "ax = rf_oob_df.plot(legend=False, marker='o', color=\"green\", figsize=(14, 7), linewidth=5)\r\n",
        "ax.set(ylabel='out-of-bag error');"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "rf = RF.set_params(n_estimators=200)\r\n",
        "\r\n",
        "y_pred_rf = rf.predict(X_test)\r\n",
        "precision_rf, recall_rf = (round(float(x),2) for x in list(score(y_test,\r\n",
        "                                                                    y_pred_rf,\r\n",
        "                                                                    average='weighted'))[:-2])\r\n",
        "rf_stats = pd.Series({'precision':precision_rf,\r\n",
        "                      'recall':recall_rf,\r\n",
        "                      'accuracy':round(accuracy_score(y_test, y_pred_rf), 2),\r\n",
        "                      'f1score':round(f1_score(y_test, y_pred_rf), 2),\r\n",
        "                      'auc': round(roc_auc_score(y_test, y_pred_rf),2)}, name='Random Forest')\r\n",
        "# Report outcomes\r\n",
        "pd.DataFrame(classification_report(y_test, y_pred_rf, output_dict=True)).iloc[:3,:2]"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Decision Tree\r\n",
        "dt = DecisionTreeClassifier(random_state=42)\r\n",
        "dt = dt.fit(X_train, y_train)\r\n",
        "dt.tree_.node_count, dt.tree_.max_depth"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "\r\n",
        "y_train_pred = dt.predict(X_train)\r\n",
        "y_pred_dt = dt.predict(X_test)\r\n",
        "\r\n",
        "precision_dt, recall_dt = (round(float(x),2) for x in list(score(y_test,\r\n",
        "                                                                y_pred_dt,\r\n",
        "                                                                average='weighted'))[:-2])\r\n",
        "# adding dt stats to metrics DataFrame\r\n",
        "dt_stats = pd.Series({'precision':precision_dt,\r\n",
        "                      'recall':recall_dt,\r\n",
        "                      'accuracy':round(accuracy_score(y_test, y_pred_dt), 2),\r\n",
        "                      'f1score':round(f1_score(y_test, y_pred_dt), 2),\r\n",
        "                      'auc': round(roc_auc_score(y_test, y_pred_dt),2)}, name='Decision Tree')\r\n",
        "# Report outcomes\r\n",
        "pd.DataFrame(classification_report(y_test, y_pred_dt, output_dict=True)).iloc[:3,:2]"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "fig, axList = plt.subplots(nrows=2, ncols=2)\r\n",
        "axList = axList.flatten()\r\n",
        "fig.set_size_inches(12, 10)\r\n",
        "\r\n",
        "\r\n",
        "models = coeff_labels = ['lr', 'knn', 'dt', 'rf']\r\n",
        "cm = [confusion_matrix(y_test, y_pred_lr),\r\n",
        "      confusion_matrix(y_test, y_pred_knn),\r\n",
        "      confusion_matrix(y_test, y_pred_dt),\r\n",
        "      confusion_matrix(y_test, y_pred_rf)]\r\n",
        "labels = ['False', 'True']\r\n",
        "\r\n",
        "for ax,model, idx in zip(axList, models, range(0,4)):\r\n",
        "    sns.heatmap(cm[idx], ax=ax, annot=True, fmt='d', cmap='winter');\r\n",
        "    ax.set(title=model);\r\n",
        "    ax.set_xticklabels(labels, fontsize=20);\r\n",
        "    ax.set_yticklabels(labels, fontsize=20);\r\n",
        "    ax.set_ylabel('Prediction', fontsize=25);\r\n",
        "    ax.set_xlabel('Ground Truth', fontsize=25)\r\n",
        "    \r\n",
        "plt.tight_layout()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "metrics.append([lr_stats, knn_stats, dt_stats, rf_stats])"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import seaborn as sns\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from sklearn.preprocessing import StandardScaler\r\n",
        "\r\n"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {}
    }
  ]
}